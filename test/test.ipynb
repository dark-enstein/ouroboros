{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0774e76f",
   "metadata": {},
   "outputs": [],
   "source": "import sys, os\nsys.path.insert(0, os.path.join(os.path.dirname(os.path.abspath(\"__file__\")), \"..\"))\n\npassed = 0\nfailed = 0\n\ndef check(name, condition):\n    global passed, failed\n    if condition:\n        passed += 1\n        print(f\"  ✓ {name}\")\n    else:\n        failed += 1\n        print(f\"  ✗ {name}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6f1bf9",
   "metadata": {},
   "outputs": [],
   "source": "# ── Test 1: Data Models (type.py) ──\nprint(\"Test 1: Data Models\")\n\nfrom core.type import (\n    Attachment, Reactions, Comment, Analytics, Post, Profile,\n    Follows, SocialGraph, EngagementRecord, Filters, UserData,\n    ScoredPost, get_current_user, get_current_posts,\n)\nfrom datetime import datetime, timezone\n\n# Reactions\nr = Reactions(data={\"like\": 10, \"dislike\": 3})\ncheck(\"Reactions.likes\", r.likes == 10)\ncheck(\"Reactions.dislikes\", r.dislikes == 3)\ncheck(\"Reactions.net_score\", r.net_score == 7)\n\nr_default = Reactions()\ncheck(\"Reactions default zeros\", r_default.likes == 0 and r_default.dislikes == 0)\n\n# Comment\nc = Comment(id=\"c1\", owner=\"alice\", content=\"test\")\ncheck(\"Comment fields\", c.id == \"c1\" and c.owner == \"alice\")\ncheck(\"Comment default reactions\", c.reactions.likes == 0)\n\n# Analytics engagement score\na = Analytics(\n    reactions=Reactions(data={\"like\": 10, \"dislike\": 2}),\n    comments=[\n        Comment(id=\"c1\", owner=\"a\", content=\"x\", reactions=Reactions(data={\"like\": 3, \"dislike\": 0})),\n        Comment(id=\"c2\", owner=\"b\", content=\"y\", reactions=Reactions(data={\"like\": 1, \"dislike\": 1})),\n    ]\n)\n# formula: likes - dislikes*1.5 + comments*2.0 + comment_reactions_net*0.5\n# = 10 - 3.0 + 4.0 + (3 + 0)*0.5 = 12.5\nexpected_eng = 10 - (2 * 1.5) + (2 * 2.0) + ((3 + 0) * 0.5)\ncheck(\"Analytics.engagement_score\", abs(a.engagement_score - expected_eng) < 0.01)\n\n# Post\np = Post(id=\"p1\", title=\"Test\", owner=\"bob\", content=\"hello\", tags=[\"a\", \"b\"])\ncheck(\"Post created_at is datetime\", isinstance(p.created_at, datetime))\ncheck(\"Post tags\", p.tags == [\"a\", \"b\"])\ncheck(\"Post.hydrate() returns self\", p.hydrate() is p)\ncheck(\"Post default network is 'out'\", p.network == \"out\")\n\n# get_current_posts from dict with key\nraw_dict = {\"posts\": [\n    {\"id\": \"p1\", \"title\": \"T\", \"owner\": \"o\", \"content\": \"c\"},\n    {\"id\": \"p2\", \"title\": \"T2\", \"owner\": \"o2\", \"content\": \"c2\"},\n]}\nposts = get_current_posts(raw_dict)\ncheck(\"get_current_posts from dict\", len(posts) == 2 and posts[0].id == \"p1\")\n\n# get_current_posts from list\nposts2 = get_current_posts([{\"id\": \"p3\", \"title\": \"T\", \"owner\": \"o\", \"content\": \"c\"}])\ncheck(\"get_current_posts from list\", len(posts2) == 1)\n\n# UserData round-trip\nraw_user = {\n    \"id\": \"u1\",\n    \"profile\": {\"name\": \"Test\", \"country\": \"US\", \"preferences\": \"eng\", \"verified\": False},\n    \"socialgraph\": {\"followers\": {\"len\": 5, \"chain\": []}, \"following\": {\"len\": 3, \"chain\": []}, \"friends\": []},\n    \"anti_filters\": {\"disliked_posts\": [\"p1\"], \"blocked_owners\": [\"spam_bot\"], \"blocked_tags\": [\"nsfw\"], \"engagement_history\": []},\n}\nu = get_current_user(raw_user)\ncheck(\"UserData validates\", u.id == \"u1\" and u.profile.name == \"Test\")\ncheck(\"Filters loaded\", u.anti_filters.disliked_posts == [\"p1\"])\ncheck(\"Blocked owners loaded\", u.anti_filters.blocked_owners == [\"spam_bot\"])\n\nprint()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a72a062",
   "metadata": {},
   "outputs": [],
   "source": "# ── Test 2: Database Layer (db.py) ──\nprint(\"Test 2: Database Layer\")\n\nfrom core.db import setup_db, get_user, Database\n\n# setup_db loads both network files\ndb = setup_db()\nall_posts = db.retrieve_all()\ncheck(\"retrieve_all loads posts\", len(all_posts) == 15)\ncheck(\"All posts have IDs\", all(p.id for p in all_posts))\ncheck(\"All posts have created_at\", all(isinstance(p.created_at, datetime) for p in all_posts))\n\n# retrieve_by_network splits correctly\ndb2 = setup_db()\nin_posts, out_posts = db2.retrieve_by_network()\ncheck(\"In-network count\", len(in_posts) == 5)\ncheck(\"Out-network count\", len(out_posts) == 10)\ncheck(\"In-network tagged 'in'\", all(p.network == \"in\" for p in in_posts))\ncheck(\"Out-network tagged 'out'\", all(p.network == \"out\" for p in out_posts))\n\n# no duplicate loading of in_network.json (was a bug before)\nin_ids = [p.id for p in in_posts]\ncheck(\"No duplicate in-network posts\", len(in_ids) == len(set(in_ids)))\n\n# get_user loads valid UserData\nuser_data = get_user()\ncheck(\"get_user returns UserData\", isinstance(user_data, UserData))\ncheck(\"User has profile\", user_data.profile.name != \"\")\ncheck(\"User has social graph\", user_data.socialgraph.following.len > 0)\ncheck(\"User has engagement history\", len(user_data.anti_filters.engagement_history) > 0)\n\n# bad file path handled gracefully\nbad_db = Database([\"/nonexistent/file.json\"])\nbad_result = bad_db.retrieve_all()\ncheck(\"Missing file returns empty\", len(bad_result) == 0)\n\nprint()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9ef360",
   "metadata": {},
   "outputs": [],
   "source": "# ── Test 3: Engine — Embeddings & Similarity (models.py) ──\nprint(\"Test 3: Engine — Embeddings & Similarity\")\n\nfrom core.models import Engine, _cosine_similarity, _time_decay, _tokenize, _tf\n\n# tokenize\ncheck(\"Tokenize lowercase\", _tokenize(\"Hello World\") == [\"hello\", \"world\"])\n\n# TF\ntf_result = _tf([\"a\", \"b\", \"a\", \"a\"])\ncheck(\"TF correct\", abs(tf_result[\"a\"] - 0.75) < 0.01 and abs(tf_result[\"b\"] - 0.25) < 0.01)\n\n# cosine similarity\ncheck(\"Identical vectors sim=1\", abs(_cosine_similarity([1, 0, 1], [1, 0, 1]) - 1.0) < 0.001)\ncheck(\"Orthogonal vectors sim=0\", abs(_cosine_similarity([1, 0, 0], [0, 1, 0])) < 0.001)\ncheck(\"Zero vector sim=0\", _cosine_similarity([0, 0], [1, 1]) == 0.0)\n\n# partial similarity\nsim = _cosine_similarity([1, 1, 0], [1, 0, 1])\ncheck(\"Partial similarity in (0,1)\", 0 < sim < 1)\n\n# time decay\nrecent_post = Post(id=\"t1\", title=\"T\", owner=\"o\", content=\"c\",\n                   created_at=datetime.now(timezone.utc))\nold_post = Post(id=\"t2\", title=\"T\", owner=\"o\", content=\"c\",\n                created_at=datetime(2026, 1, 1, tzinfo=timezone.utc))\ncheck(\"Recent post decay ~1.0\", _time_decay(recent_post) > 0.95)\ncheck(\"Old post decay < recent\", _time_decay(old_post) < _time_decay(recent_post))\n\n# compute_embeddings\ntest_posts = [\n    Post(id=\"p1\", title=\"machine learning\", owner=\"a\", content=\"deep neural networks\", tags=[\"ml\", \"ai\"]),\n    Post(id=\"p2\", title=\"cooking recipe\", owner=\"b\", content=\"pasta tomato sauce\", tags=[\"food\"]),\n]\ntest_user = get_current_user({\n    \"id\": \"u1\",\n    \"profile\": {\"name\": \"ML Fan\", \"country\": \"US\", \"preferences\": \"machine learning ai\", \"verified\": True, \"interest_tags\": [\"ml\", \"ai\"]},\n    \"socialgraph\": {\"followers\": {\"len\": 0}, \"following\": {\"len\": 0}, \"friends\": []},\n})\nvocab, idf_map, vectors = Engine.compute_embeddings(test_posts, test_user)\ncheck(\"Vocab built\", len(vocab) > 0)\ncheck(\"IDF map built\", len(idf_map) > 0)\ncheck(\"Vectors match post count\", len(vectors) == 2)\ncheck(\"Vector dimensions match vocab\", len(vectors[0]) == len(vocab))\n\n# user vector should be more similar to ML post than cooking post\nuser_vec = Engine.compute_user_vector(test_user, vocab, idf_map)\nsim_ml = Engine.score_relevance(vectors[0], user_vec)\nsim_food = Engine.score_relevance(vectors[1], user_vec)\ncheck(\"ML post more relevant to ML user\", sim_ml > sim_food)\n\nprint()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97cdfdf0",
   "metadata": {},
   "outputs": [],
   "source": "# ── Test 4: Engine — Classification & Scoring ──\nprint(\"Test 4: Engine — Classification & Scoring\")\n\nfrom core.db import setup_db, get_user\n\ndb = setup_db()\nin_posts, out_posts = db.retrieve_by_network()\nuser_data = get_user()\n\nscored_in, scored_out = Engine.classify_posts(in_posts, out_posts, user_data)\n\ncheck(\"Scored in-network count matches\", len(scored_in) == len(in_posts))\ncheck(\"Scored out-network count matches\", len(scored_out) == len(out_posts))\ncheck(\"All scores > 0\", all(sp.score > 0 for sp in scored_in + scored_out))\ncheck(\"In-network sorted descending\", all(scored_in[i].score >= scored_in[i+1].score for i in range(len(scored_in)-1)))\ncheck(\"Out-network sorted descending\", all(scored_out[i].score >= scored_out[i+1].score for i in range(len(scored_out)-1)))\ncheck(\"Source labels correct (in)\", all(sp.source == \"in_network\" for sp in scored_in))\ncheck(\"Source labels correct (out)\", all(sp.source == \"out_network\" for sp in scored_out))\n\n# ScoredPost has all breakdown fields populated\nsp = scored_in[0]\ncheck(\"ScoredPost has relevance\", sp.relevance >= 0)\ncheck(\"ScoredPost has engagement\", sp.engagement >= 0)\ncheck(\"ScoredPost has recency\", 0 <= sp.recency <= 1)\n\n# ── Diversity re-ranking ──\ncombined = scored_in + scored_out\ndiverse = Engine.rank_with_diversity(combined)\ncheck(\"Diversity keeps all posts\", len(diverse) == len(combined))\n\n# check that diversity doesn't just return identical order — same-owner posts should be spread out\nowners_before = [sp.post.owner for sp in sorted(combined, key=lambda s: s.score, reverse=True)]\nowners_after = [sp.post.owner for sp in diverse]\n# at minimum diversity should move something\ncheck(\"Diversity re-ranks (order changed)\", owners_before != owners_after or len(set(owners_before)) == len(owners_before))\n\n# ── Cold-start fallback ──\ncold_posts = in_posts + out_posts\ncold_result = Engine.cold_start_fallback(cold_posts, k=5)\ncheck(\"Cold-start returns k posts\", len(cold_result) == 5)\ncheck(\"Cold-start sorted descending\", all(cold_result[i].score >= cold_result[i+1].score for i in range(len(cold_result)-1)))\ncheck(\"Cold-start scores are positive\", all(sp.score > 0 for sp in cold_result))\n\nprint()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af30983e",
   "metadata": {},
   "outputs": [],
   "source": "# ── Test 5: User Context (user.py) ──\nprint(\"Test 5: User Context\")\n\nfrom context.user.user import User\n\nuser = User()\n\ncheck(\"User loads tree\", user.tree.id == \"user_001\")\ncheck(\"User not cold start\", not user.is_cold_start)\ncheck(\"User.embedding returns UserData\", user.embedding().id == \"user_001\")\ncheck(\"get_profile_embedding\", user.get_profile_embedding().name == \"Alex Dev\")\ncheck(\"get_real_graph\", user.get_real_graph().following.len == 80)\ncheck(\"get_anti_signals\", \"post_108\" in user.get_anti_signals().disliked_posts)\ncheck(\"get_following_owners\", \"alice\" in user.get_following_owners())\ncheck(\"get_friends\", \"bob\" in user.get_friends())\n\n# pre-filtering: should remove disliked post_108\ntest_scored = [\n    ScoredPost(post=Post(id=\"post_108\", title=\"Incident\", owner=\"ops\", content=\"outage\"), score=0.5),\n    ScoredPost(post=Post(id=\"post_001\", title=\"Getting Started\", owner=\"alice\", content=\"intro\"), score=0.8),\n    ScoredPost(post=Post(id=\"post_999\", title=\"Spam\", owner=\"blocked_guy\", content=\"spam\"), score=0.3),\n]\n# add a blocked owner for testing\nuser.tree.anti_filters.blocked_owners.append(\"blocked_guy\")\n\nfiltered = user.filter(test_scored)\nfiltered_ids = [sp.post.id for sp in filtered]\ncheck(\"Pre-filter removes disliked post\", \"post_108\" not in filtered_ids)\ncheck(\"Pre-filter removes blocked owner\", \"post_999\" not in filtered_ids)\ncheck(\"Pre-filter keeps clean post\", \"post_001\" in filtered_ids)\n\n# remove test blocked owner\nuser.tree.anti_filters.blocked_owners.remove(\"blocked_guy\")\n\n# engagement recording\ninitial_history_len = len(user.tree.anti_filters.engagement_history)\nuser.record_engagement(\"post_999\", \"like\", dwell_seconds=12.0)\ncheck(\"record_engagement appends\", len(user.tree.anti_filters.engagement_history) == initial_history_len + 1)\n\nuser.record_engagement(\"post_998\", \"dislike\", dwell_seconds=1.0)\ncheck(\"Dislike auto-adds to disliked_posts\", \"post_998\" in user.tree.anti_filters.disliked_posts)\n\n# update_filters batch\nuser.update_filters({\n    \"events\": [{\"post_id\": \"post_997\", \"action\": \"click\", \"dwell_seconds\": 5.0}],\n    \"block_owners\": [\"spammer_x\"],\n    \"block_tags\": [\"crypto_scam\"],\n})\ncheck(\"update_filters adds event\", any(e.post_id == \"post_997\" for e in user.tree.anti_filters.engagement_history))\ncheck(\"update_filters blocks owner\", \"spammer_x\" in user.tree.anti_filters.blocked_owners)\ncheck(\"update_filters blocks tag\", \"crypto_scam\" in user.tree.anti_filters.blocked_tags)\n\n# update_filters with None does nothing\nprev_len = len(user.tree.anti_filters.engagement_history)\nuser.update_filters(None)\ncheck(\"update_filters(None) is no-op\", len(user.tree.anti_filters.engagement_history) == prev_len)\n\n# cold-start detection for fresh user\nfrom core.type import get_current_user\nfresh_user_data = get_current_user({\n    \"id\": \"new_user\",\n    \"profile\": {\"name\": \"New\", \"country\": \"US\", \"preferences\": \"\", \"verified\": False},\n    \"socialgraph\": {\"followers\": {\"len\": 0}, \"following\": {\"len\": 0}, \"friends\": []},\n    \"anti_filters\": {\"engagement_history\": []},\n})\ncheck(\"Empty history = cold start data\", len(fresh_user_data.anti_filters.engagement_history) == 0)\n\nprint()"
  },
  {
   "cell_type": "code",
   "id": "3ydv8gpmlqs",
   "source": "# ── Test 6: Utils — rank() and filter() ──\nprint(\"Test 6: Utils — rank & filter\")\n\nfrom core.utils import rank, filter\n\n# rank normalizes scores to [0, 1]\ntest_ranked = [\n    ScoredPost(post=Post(id=\"a\", title=\"A\", owner=\"x\", content=\"c\"), score=0.8),\n    ScoredPost(post=Post(id=\"b\", title=\"B\", owner=\"y\", content=\"c\"), score=0.4),\n    ScoredPost(post=Post(id=\"c\", title=\"C\", owner=\"z\", content=\"c\"), score=0.2),\n]\nranked = rank(test_ranked)\ncheck(\"rank sorts descending\", ranked[0].post.id == \"a\")\ncheck(\"rank normalizes top to 1.0\", abs(ranked[0].score - 1.0) < 0.001)\ncheck(\"rank normalizes proportionally\", ranked[1].score < ranked[0].score)\ncheck(\"rank empty input\", rank([]) == [])\n\n# filter — deduplication\ndup_posts = [\n    ScoredPost(post=Post(id=\"dup\", title=\"T\", owner=\"o\", content=\"c\"), score=0.5),\n    ScoredPost(post=Post(id=\"dup\", title=\"T\", owner=\"o\", content=\"c\"), score=0.3),\n]\ndeduped = filter(dup_posts)\ncheck(\"filter removes duplicates\", len(deduped) == 1)\n\n# filter — blocked keywords\nspam_post = ScoredPost(post=Post(id=\"s1\", title=\"Get rich SCAM\", owner=\"o\", content=\"c\"), score=0.5)\nclean_post = ScoredPost(post=Post(id=\"s2\", title=\"Good Post\", owner=\"o\", content=\"hello\"), score=0.5)\nfiltered = filter([spam_post, clean_post])\ncheck(\"filter removes blocked keyword\", len(filtered) == 1 and filtered[0].post.id == \"s2\")\n\n# filter — high dislike ratio suppression\ntoxic = Post(id=\"toxic\", title=\"T\", owner=\"o\", content=\"c\",\n             analytics=Analytics(reactions=Reactions(data={\"like\": 3, \"dislike\": 5})))\ntoxic_sp = ScoredPost(post=toxic, score=0.5)\nok_post = ScoredPost(post=Post(id=\"ok\", title=\"T\", owner=\"o2\", content=\"c\"), score=0.5)\nresult = filter([toxic_sp, ok_post])\ncheck(\"filter suppresses high-dislike ratio\", len(result) == 1 and result[0].post.id == \"ok\")\n\n# filter — with user context (blocked owners/tags)\ntest_user_data = get_current_user({\n    \"id\": \"u1\",\n    \"profile\": {\"name\": \"T\", \"country\": \"US\", \"preferences\": \"\", \"verified\": False},\n    \"socialgraph\": {\"followers\": {\"len\": 0}, \"following\": {\"len\": 0}, \"friends\": []},\n    \"anti_filters\": {\"blocked_owners\": [\"bad_actor\"], \"blocked_tags\": [\"nsfw\"], \"disliked_posts\": [\"hated_post\"]},\n})\nposts_to_filter = [\n    ScoredPost(post=Post(id=\"hated_post\", title=\"T\", owner=\"o\", content=\"c\"), score=0.5),\n    ScoredPost(post=Post(id=\"bad_owner\", title=\"T\", owner=\"bad_actor\", content=\"c\"), score=0.5),\n    ScoredPost(post=Post(id=\"nsfw_post\", title=\"T\", owner=\"o\", content=\"c\", tags=[\"nsfw\"]), score=0.5),\n    ScoredPost(post=Post(id=\"good_post\", title=\"T\", owner=\"o\", content=\"clean\"), score=0.5),\n]\nresult = filter(posts_to_filter, test_user_data)\nresult_ids = [sp.post.id for sp in result]\ncheck(\"filter removes user-disliked\", \"hated_post\" not in result_ids)\ncheck(\"filter removes blocked owner\", \"bad_owner\" not in result_ids)\ncheck(\"filter removes blocked tag\", \"nsfw_post\" not in result_ids)\ncheck(\"filter keeps clean post\", \"good_post\" in result_ids)\n\nprint()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "uu8i457j1pn",
   "source": "# ── Test 7: Embedding Retrieval (retrieve.py) ──\nprint(\"Test 7: Embedding Retrieval\")\n\nfrom datasets.retrieve import Embedding\n\nembed = Embedding()\ncheck(\"Embedding loads in-network\", len(embed.get_innetwork_posts()) == 5)\ncheck(\"Embedding loads out-network\", len(embed.get_outnetwork_posts()) == 10)\ncheck(\"get() returns all\", len(embed.get()) == 15)\n\n# classify returns scored posts\nuser_data = get_user()\nscored_in, scored_out = embed.classify(user_data)\ncheck(\"classify returns ScoredPost in\", all(isinstance(sp, ScoredPost) for sp in scored_in))\ncheck(\"classify returns ScoredPost out\", all(isinstance(sp, ScoredPost) for sp in scored_out))\ncheck(\"classify in count\", len(scored_in) == 5)\ncheck(\"classify out count\", len(scored_out) == 10)\n\n# hydrate\nhydrated = embed.hydrate(embed.get_innetwork_posts())\ncheck(\"hydrate returns same posts\", len(hydrated) == 5)\ncheck(\"hydrated posts have content\", all(p.content for p in hydrated))\n\nprint()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "c6j7juaove",
   "source": "# ── Test 8: Full Pipeline Integration ──\nprint(\"Test 8: Full Pipeline Integration\")\n\nfrom datasets.retrieve import Embedding as E2\nfrom context.user.user import User as U2\nfrom core.utils import filter as post_filter, rank as final_rank\nfrom core.models import Engine as E\n\n# step 1: load\nemb = E2()\ntotal_posts = len(emb.get())\ncheck(\"Pipeline: posts loaded\", total_posts == 15)\n\n# step 2: user\nu = U2()\nud = u.embedding()\ncheck(\"Pipeline: user loaded\", ud.id == \"user_001\")\n\n# step 3: classify\ns_in, s_out = emb.classify(ud)\ncheck(\"Pipeline: classification done\", len(s_in) + len(s_out) == total_posts)\n\n# step 4: combine\ncombined = s_in + s_out\ncheck(\"Pipeline: combined\", len(combined) == total_posts)\n\n# step 5: pre-filter\nprefiltered = u.filter(combined)\ncheck(\"Pipeline: pre-filter reduces\", len(prefiltered) <= len(combined))\ncheck(\"Pipeline: disliked post_108 removed\", all(sp.post.id != \"post_108\" for sp in prefiltered))\n\n# step 6: rank\nranked = final_rank(prefiltered)\ncheck(\"Pipeline: ranked scores normalized\", ranked[0].score == 1.0)\n\n# step 7: diversity\ndiverse = E.rank_with_diversity(ranked)\ncheck(\"Pipeline: diversity preserves count\", len(diverse) == len(ranked))\n\n# step 8: post-filter\nfinal = post_filter(diverse, ud)\ncheck(\"Pipeline: post-filter produces results\", len(final) > 0)\ncheck(\"Pipeline: no duplicates in final\", len(set(sp.post.id for sp in final)) == len(final))\n\n# verify ordering is sensible — top post should have score >= all others\ncheck(\"Pipeline: final is sorted-ish\", final[0].score >= final[-1].score)\n\n# verify the feed has posts from multiple owners (diversity working)\nunique_owners = set(sp.post.owner for sp in final[:5])\ncheck(\"Pipeline: top 5 has diverse owners\", len(unique_owners) >= 3)\n\n# step 9: feedback loop\nu.update_filters({\"events\": [{\"post_id\": final[0].post.id, \"action\": \"like\", \"dwell_seconds\": 20.0}]})\ncheck(\"Pipeline: feedback recorded\", any(\n    e.post_id == final[0].post.id and e.action == \"like\"\n    for e in u.tree.anti_filters.engagement_history\n))\n\nprint()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "wuiqrjaca5m",
   "source": "# ── Summary ──\nprint(\"=\" * 50)\nprint(f\"Results: {passed} passed, {failed} failed, {passed + failed} total\")\nif failed == 0:\n    print(\"All tests passed.\")\nelse:\n    print(f\"FAILURES: {failed} test(s) failed.\")\nprint(\"=\" * 50)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepr-tf3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}